---
title: "Transforming Feature Space to Interpret Machine Learning Models"
subtitle: "A Remote-Sensing Case Study Using the Random Forest Classifier"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{gabor_rf}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(wiml)
```

# Preface{-}

This vignette walks you through the analyses performed for the paper that introduces the novel model interpretation approach implemented in the `wiml` package. Please refer to that paper for conceptual and formal details, and cite it when using `wiml` or referring to the methods and results presented herein.

> Brenning, A. (2011). Transforming Feature Space to Interpret Machine Learning Models. arXiv:submit/3691062, submitted 9 Apr 2021.

The `wiml` package serves as a thin wrapper around other packages implementing ALE plots, partial dependence plots and other post-hoc model-agnostic interpretation tools. In this vignette, I will use `iml`, and creating a version of this vignette for `DALEX` is also on my to-do list. Please remind me in case that's what you're looking for...

Several of the following steps are computationally expensive and will be slow even on a workstation since the `iml` package, which does all the heavy lifting, does not seem to make full use of the parallel *workers* offered to it. Either way, we're prepared for parallel execution:

# Getting started

## Work environment

Make sure that all required packages and their dependencies are installed and up-to-date. `wiml` is currently only available via Github, so you will have to use `devtools` to install it.

```{r load_packages, echo = TRUE, results = "hide"}
# install.packages("devtools")
# install_github("https://github.com/alexanderbrenning/wiml")
library("iml")
library("wiml")
library("magrittr")
library("randomForest")
library("sperrorest")
```

In addition, you will need the packages `stringr`, `purrr`. Packages for parallelization are optional: `future`, `future.callr`. To parallelize computation where possible, (optionally) use the following call with the appropriate number of workers for your computing environment:

```{r parallelization}
future::plan(future.callr::callr, workers = 44)
```

Let's try to be reproducible (may not be successful when running in parallel), and prepare some settings for ALE and partial dependence plots:

```{r set_seed, results='hide'}
set.seed(444)
ale_grid_size <- 20
pdp_grid_size <- 100
```


## Prepare data and model formulas

Land cover classification is a standard task in remote sensing, which often uses a large set of features ($20\le p\le200$) - for example, multitemporal spectral reflectances and derived vegetation indices and texture attributes, or even hyperspectral features. Many of these features are strongly correlated with each other, and they are often semantically grouped.

We will look at a special and rather challenging 

```{r code}
data(gabor, package = "wiml")
d <- gabor

dtrain <- d[d$area == "LN",]
dtest <- d[d$area == "CAT",]
sel_test <- c(sample(which(dtest$class == "FALSE"), size = 500),
         sample(which(dtest$class == "TRUE"), size = 500))
dtest <- dtest[sel_test,]
sel_train <- c(sample(which(dtrain$class == "FALSE"), size = 500),
              sample(which(dtrain$class == "TRUE"), size = 500))
dtrain <- dtrain[sel_train,]
d <- rbind(dtrain, dtest)


# Set up lists of features and model formulas:
gabor_vars <- stringr::str_subset(colnames(d), "^m.*e.*g.*")
terrain_vars <- c("dem", "slope", "pisr", 
                  "cslope", "log.carea", "log.cheight")
yvar <- "class"

# Features for plain PCA transformation:
xvars <- c(gabor_vars, terrain_vars)
uvars <- NULL

# List for structured PCA:
xvars_list <- list(
  "Gabor" = gabor_vars
)
uvars_list <- terrain_vars

# Formula for fitting the model with all features:
fo <- as.formula(paste(yvar, "~", 
                       paste(xvars, collapse = " + ")))

# Formulas for models using subset of features:
fo_ex <- list(
  Terrain = as.formula(paste(yvar, "~", 
                             paste(terrain_vars, collapse = " + "))),
  Gabor = as.formula(paste(yvar, "~",
                           paste(xvars_list$Gabor, collapse = " + ")))
)

# PCA transformation: 
# names of transformed variables of interest
pc_vars <- paste0("PC", 1:6)




d[,xvars] <- d[,xvars] %>% 
  purrr::map(DescTools::Winsorize, probs = c(0.02, 0.98)) %>%
  as.data.frame()

dtest <- d[ 1001:2000 , ]
d <- d[ 1:1000 , ]
```


## Exploratory analysis

```{r exploratory}
# For each Gabor feature, find its largest (absolute) 
# correlation with other Gabor features: 
gabor_corrs <- abs(cor(d[, gabor_vars])) %>% 
  as.data.frame() %>% 
  purrr::map_df(sort, decreasing = TRUE) %>% 
  purrr::map_dbl(dplyr::nth, n = 2)
med_corr_gabor <- median(gabor_corrs)
min_corr_gabor <- min(gabor_corrs)

terrain_corrs <- abs(cor(d[, terrain_vars])) %>% 
  as.data.frame() %>% 
  purrr::map_df(sort, decreasing = TRUE) %>% 
  purrr::map_dbl(dplyr::nth, n = 2)
med_corr_terrain <- median(terrain_corrs)
min_corr_terrain <- min(terrain_corrs)

terrain_gabor_corrs <- abs(cor(d[,terrain_vars], d[,gabor_vars])) %>% 
  as.data.frame() %>% 
  purrr::map_df(sort, decreasing = TRUE) %>% 
  purrr::map_dbl(dplyr::nth, n = 2)
med_corr_terrain_gabor <- median(terrain_gabor_corrs)
max_corr_terrain_gabor <- max(terrain_gabor_corrs)
```



```{r code}
# Train a random forest model using the Laguna Negra 
# training area:

fit <- randomForest::randomForest(formula = fo, data = d)

simple_predictor <- Predictor$new(fit, data = d, y = yvar, 
                                  type = "prob", class = "TRUE")
simple_effs <- FeatureEffects$new(simple_predictor, 
                                  features = xvars, 
                                  method = "ale", 
                                  grid.size = ale_grid_size)

## Prepare warper:
simple_warp <- pca_warper(d, xvars = xvars, yvar = yvar, 
                          uvars = uvars)
simply_warped_fit <- warp_fitted_model(fit, 
                                       warper = simple_warp)

simply_warped_predictor <- 
  Predictor$new(simply_warped_fit, 
                data = warp(d, warper = simple_warp), 
                y = yvar, type = "prob", class = "TRUE")
simply_warped_effs <- FeatureEffects$new(simply_warped_predictor, 
                     features = pc_vars, 
                     method = "ale", grid.size = ale_grid_size)


struc_warp <- strucpca_warper(d, xvars = xvars_list, yvar = yvar, 
                          uvars = uvars_list, 
                          wvars = names(xvars_list))
struc_warped_fit <- warp_fitted_model(fit, 
                                      warper = struc_warp)

imp_struc_w_predictor <- Predictor$new(struc_warped_fit, 
                                       data = warp(dtest, warper = struc_warp), 
                                       y = yvar, 
                                       type = "response")
imp <- FeatureImp$new(imp_struc_w_predictor, 
                      loss = "ce", compare = "difference", 
                      n.repetitions = 100)
#plot(imp)
#imp$results$feature[1:8]

imp10 <- FeatureImp$new(imp_struc_w_predictor, 
                      loss = "ce", compare = "difference",
                      features = imp$results$feature[1:10],
                      n.repetitions = 100)

struc_features <- c("Gabor1", "Gabor2", "Gabor3", 
                    stringr::str_subset(imp$results$feature, "Gabor", negate = TRUE)[1:3])


struc_warped_predictor <- Predictor$new(struc_warped_fit, 
                                        data = warp(d, warper = struc_warp), 
                                        y = yvar, type = "prob", 
                                        class = "TRUE")
struc_warped_effs <- FeatureEffects$new(struc_warped_predictor, 
                                        features = struc_features, 
                                        method = "ale", 
                                        grid.size = ale_grid_size)
#plot(struc_warped_effs)

struc_warped_effs_ale <- FeatureEffects$new(struc_warped_predictor, 
                                            features = struc_features, 
                                            method = "ale", 
                                            grid.size = ale_grid_size)
struc_warped_effs_pdp <- FeatureEffects$new(struc_warped_predictor, 
                                            features = struc_features, 
                                            method = "pdp", 
                                            grid.size = pdp_grid_size)

struc_warped_effs_2d <- FeatureEffect$new(struc_warped_predictor, 
                                          feature = c("Gabor1", "Gabor2"), 
                                          method = "ale", 
                                          grid.size = rep(min(40,grid_size),2))

struc_warped_effs_2d_ale <- 
  FeatureEffect$new(struc_warped_predictor, 
                    feature = c("Gabor1", "Gabor2"), 
                    method = "ale", grid.size = c(20,20))
struc_warped_effs_2d_ale2 <- 
  FeatureEffect$new(struc_warped_predictor, 
                    feature = c("Gabor3", "Gabor4"), 
                    method = "ale", grid.size = c(20,20))
struc_warped_effs_2d_pdp <- 
  FeatureEffect$new(struc_warped_predictor, 
                    feature = c("Gabor1", "Gabor2"), 
                    method = "pdp", grid.size = c(40,40))
struc_warped_effs_2d_pdp2 <- 
  FeatureEffect$new(struc_warped_predictor, 
                    feature = c("Gabor3", "Gabor4"), 
                    method = "pdp", grid.size = c(40,40))


# Estimate the mean cross-validation accuracy
# using two-fold cross-validation between the two
# regions, Laguna Negra and Catedral:
estimate_accuracy <- function(formula, data = d) {
  cvres <- sperrorest::sperrorest(formula, data = data, 
                      model_fun = randomForest,
                      pred_args = list(type = "response"), 
                      smp_fun = partition_factor,
                      smp_args = list(fac = "region", 
                      repetition=1:1))
  summary(cvres$error_rep)["test_accuracy", "mean"]
}



# Accuracy in two-fold cross-validation:
dcv <- rbind(d, dtest)
dcv$region <- as.factor(c(rep("LN", nrow(d)), rep("CAT", nrow(dtest))))

acc <- estimate_accuracy(fo, data = dcv)
acc_Terrain <- estimate_accuracy(fo_ex$Terrain, data = dcv)
acc_Gabor <- estimate_accuracy(fo_ex$Gabor, data = dcv)
acc_ex <- c(acc_Terrain, acc_Gabor)
names(acc_ex) <- names(fo_ex)
accdiff <- acc - acc_ex




# For comparison, train and cross-validate a model
# using the PC-transformed features:

pcd <- warp(dcv, warper = simple_warp)
pcd$region <- dcv$region
pcfo <- as.formula(paste("class ~", 
                         paste0(colnames(simple_warp$pca$x), 
                                collapse = " + ")))
pcfit <- randomForest(formula = pcfo, data = pcd)
pc_acc <- estimate_accuracy(pcfo, data = pcd)


# Save all results so they can be used in the paper:
save.image(file = here::here("cache/wiml_gabor_results_rf.Rdata"))

```


# References{-}

Brenning, A. (2011). Transforming Feature Space to Interpret Machine Learning Models. arXiv:submit/3691062, submitted 9 Apr 2021.
  
  
